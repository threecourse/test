{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Microsoft/LightGBM/blob/master/examples/python-guide/simple_example.py\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run(flag=0):\n",
    "    df_train = pd.read_csv('data/regression.train', header=None, sep='\\t')\n",
    "    df_test = pd.read_csv('data/regression.test', header=None, sep='\\t')\n",
    "\n",
    "    y_train = df_train[0]\n",
    "    y_test = df_test[0]\n",
    "    X_train = df_train.drop(0, axis=1)\n",
    "    X_test = df_test.drop(0, axis=1)\n",
    "\n",
    "    # create dataset for lightgbm\n",
    "    if flag == 0:\n",
    "        print(\"run by flag 0 - X-test, y-test\")\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "    elif flag == 1:\n",
    "        print(\"run by flag 1 - X-train, zeros\")\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_test, np.zeros(y_test.shape), reference=lgb_train)\n",
    "    else:\n",
    "        print(\"run by flag 2 - X-train, y-train\")\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_train, y_train, reference=lgb_train)\n",
    "\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        \"random_state\": 71\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=3,\n",
    "                    valid_sets=[lgb_train, lgb_eval],\n",
    "                    early_stopping_rounds=5)\n",
    "    print(gbm.feature_importance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run by flag 0 - X-test, y-test\n",
      "[1]\ttraining's l2: 0.243597\ttraining's l1: 0.492494\tvalid_1's l2: 0.24288\tvalid_1's l1: 0.491812\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's l2: 0.239477\ttraining's l1: 0.488088\tvalid_1's l2: 0.239307\tvalid_1's l1: 0.48798\n",
      "[3]\ttraining's l2: 0.235706\ttraining's l1: 0.483953\tvalid_1's l2: 0.235559\tvalid_1's l1: 0.483905\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3]\ttraining's l2: 0.235706\ttraining's l1: 0.483953\tvalid_1's l2: 0.235559\tvalid_1's l1: 0.483905\n",
      "[ 0  1  0  7  3 10  0  0  0  2  0  0  0  4  0  0  0  0  2  4  0  0 12  1\n",
      " 12 10 14  8]\n"
     ]
    }
   ],
   "source": [
    "run(flag=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run by flag 1 - X-train, zeros\n",
      "[1]\ttraining's l2: 0.243597\ttraining's l1: 0.492494\tvalid_1's l2: 0.281387\tvalid_1's l1: 0.530319\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's l2: 0.239477\ttraining's l1: 0.488088\tvalid_1's l2: 0.281462\tvalid_1's l1: 0.530135\n",
      "[3]\ttraining's l2: 0.235706\ttraining's l1: 0.483953\tvalid_1's l2: 0.281838\tvalid_1's l1: 0.530184\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3]\ttraining's l2: 0.235706\ttraining's l1: 0.483953\tvalid_1's l2: 0.281838\tvalid_1's l1: 0.530184\n",
      "[ 0  1  0  7  3 10  0  0  0  2  0  0  0  4  0  0  0  0  2  4  0  0 12  1\n",
      " 12 10 14  8]\n"
     ]
    }
   ],
   "source": [
    "run(flag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run by flag 2 - X-train, y-train\n",
      "[1]\ttraining's l2: 0.243597\ttraining's l1: 0.492494\tvalid_1's l2: 0.243597\tvalid_1's l1: 0.492494\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's l2: 0.239477\ttraining's l1: 0.488088\tvalid_1's l2: 0.239477\tvalid_1's l1: 0.488088\n",
      "[3]\ttraining's l2: 0.235706\ttraining's l1: 0.483953\tvalid_1's l2: 0.235706\tvalid_1's l1: 0.483953\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3]\ttraining's l2: 0.235706\ttraining's l1: 0.483953\tvalid_1's l2: 0.235706\tvalid_1's l1: 0.483953\n",
      "[ 0  1  0  7  3 10  0  0  0  2  0  0  0  4  0  0  0  0  2  4  0  0 12  1\n",
      " 12 10 14  8]\n"
     ]
    }
   ],
   "source": [
    "run(flag=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
